{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing stance detection (Opinion mining) for tweets based on misinformation targets using the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WWUH7NdMHGEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "\u001b[K     |████████████████████████████████| 176 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytorch_transformers) (0.0.44)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.18.24-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytorch_transformers) (1.6.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytorch_transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytorch_transformers) (4.50.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytorch_transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytorch_transformers) (2.23.0)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sacremoses->pytorch_transformers) (0.16.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.22.0,>=1.21.24\n",
      "  Downloading botocore-1.21.24-py3-none-any.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 1.7 MB/s eta 0:00:01     |████████▉                       | 2.2 MB 2.2 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torch>=1.0.0->pytorch_transformers) (0.18.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->pytorch_transformers) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->pytorch_transformers) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->pytorch_transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->pytorch_transformers) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.24->boto3->pytorch_transformers) (2.8.1)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, sentencepiece, pytorch-transformers\n",
      "Successfully installed boto3-1.18.24 botocore-1.21.24 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sentencepiece-0.1.96\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5395501594c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_transformers'"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from google.colab import drive\n",
    "import logging\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "!pip install pytorch_transformers \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from pytorch_transformers import BertConfig, BertTokenizer, BertModel, AdamW\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ziKrk2W0iBY9",
    "outputId": "0be2bb7a-2438-4cd0-a953-57061fccf7f3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3b8a479202a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zsa9-FuTHN-R",
    "outputId": "d9f936b3-f64a-4175-d362-7773efe1dedf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/harithav/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/harithav/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "1NEwaH-zDiX5",
    "outputId": "1bf1cb47-3a39-497a-842f-a31745879e96"
   },
   "outputs": [],
   "source": [
    "# Word lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text, re.UNICODE)\n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(' ')]\n",
    "    text = [lemmatizer.lemmatize(token, 'v') for token in text]\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    text = text.lstrip().rstrip()\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YikvGoScfiiz"
   },
   "outputs": [],
   "source": [
    "logging.getLogger('pytorch_transformers').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsTCVtZmfrbi",
    "outputId": "b3b2cf63-6e89-483c-820c-94454ef2da13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE FOUND: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"DEVICE FOUND: %s\" % DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LI7hT5t4gBVv"
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "torch.manual_seed(seed=SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzK9F-dYgEAp"
   },
   "outputs": [],
   "source": [
    "# Initialize Hyperparameters\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "PRETRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "NUM_PRETRAINED_BERT_LAYERS = 1\n",
    "MAX_TOKENIZATION_LENGTH = 512\n",
    "NUM_CLASSES = 4 # agree, disagree, no_stance, not_relevant\n",
    "TOP_DOWN = True\n",
    "NUM_RECURRENT_LAYERS = 1\n",
    "HIDDEN_SIZE = 256\n",
    "REINITIALIZE_POOLER_PARAMETERS = True\n",
    "USE_BIDIRECTIONAL = True\n",
    "DROPOUT_RATE = 0.6\n",
    "AGGREGATE_ON_CLS_TOKEN = True\n",
    "CONCATENATE_HIDDEN_STATES = True\n",
    "\n",
    "APPLY_CLEANING = True\n",
    "TRUNCATION_METHOD = 'head-only'\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "BERT_LEARNING_RATE = 1e-5\n",
    "CUSTOM_LEARNING_RATE = 1e-4\n",
    "BETAS = (0.9, 0.999)\n",
    "BERT_WEIGHT_DECAY = 0.01\n",
    "EPS = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L11timVJih3P"
   },
   "source": [
    "### Finetuned Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dBeLwOujdTK"
   },
   "outputs": [],
   "source": [
    "targets = [\"RNA alters a person's DNA when taking the COVID-19 vaccine.\",\n",
    "            \"The COVID-19 vaccine causes infertility or miscarriages in women.\",\n",
    "            \"Natural COVID-19 immunity is better than immunity derived from a COVID-19 vaccine.\",\n",
    "            \"The COVID-19 vaccine causes Bell's palsy.\",\n",
    "            \"The COVID-19 vaccine contains tissue from aborted fetuses.\",\n",
    "            \"The COVID-19 vaccine was developed to control the general population either through microchip tracking or nanotransducers in our brains.\",\n",
    "            \"More people will die as a result of a negative side effect to the COVID-19 vaccine than would actually die from the coronavirus.\",\n",
    "            \"There are severe side effects of the coronavirus vaccines, worse than having the virus.\"]\n",
    "target_idx = [1,2,3,4,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fg3kSUr7vQIZ"
   },
   "outputs": [],
   "source": [
    "class FineTunedBert(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_pretrained_bert_layers, max_tokenization_length, vocab_file = '',\n",
    "                 num_classes=1, top_down=True, num_recurrent_layers=1, use_bidirectional=False,\n",
    "                 hidden_size=128, reinitialize_pooler_parameters=False, dropout_rate=0.10,\n",
    "                 aggregate_on_cls_token=True, concatenate_hidden_states=False, use_gpu=False):\n",
    "        super(FineTunedBert, self).__init__()\n",
    "        self.num_recurrent_layers = num_recurrent_layers\n",
    "        self.use_bidirectional = use_bidirectional\n",
    "        self.hidden_size = hidden_size\n",
    "        self.aggregate_on_cls_token = aggregate_on_cls_token\n",
    "        self.concatenate_hidden_states = concatenate_hidden_states\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        # Tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
    "        self.tokenizer.max_len = max_tokenization_length\n",
    "        self.tokenizer.vocab_file = vocab_file\n",
    "\n",
    "        # Obtain global BERT config\n",
    "        self.config = BertConfig.from_pretrained(pretrained_model_name)\n",
    "        # Extract all parameters (weights and bias matrices) for the 12 layers\n",
    "        all_states_dict = BertModel.from_pretrained(pretrained_model_name,\n",
    "                                                    config=self.config).state_dict()\n",
    "\n",
    "        # Obtain customized BERT config\n",
    "        self.config.max_position_embeddings = max_tokenization_length\n",
    "        self.config.num_hidden_layers = num_pretrained_bert_layers\n",
    "        self.config.output_hidden_states = True\n",
    "        self.config.output_attentions = True\n",
    "\n",
    "        # Obtain pretrained BERT model & all its learnable parameters\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name,\n",
    "                                              config=self.config)\n",
    "        current_states_dict = self.bert.state_dict()\n",
    "\n",
    "        if top_down:\n",
    "            for param in current_states_dict.keys():\n",
    "                if 'pooler' not in param or not reinitialize_pooler_parameters:\n",
    "                    current_states_dict[param] = all_states_dict[param]\n",
    "                else:\n",
    "                    if 'weight' in param:\n",
    "                        current_states_dict[param] = torch.ones(self.config.hidden_size,\n",
    "                                                                self.config.hidden_size)\n",
    "                    elif 'bias' in param:\n",
    "                        current_states_dict[param] = torch.zeros(self.config.hidden_size)\n",
    "\n",
    "        else:\n",
    "            align = 5 + ((12 - num_pretrained_bert_layers) * 16)\n",
    "            for index, param in enumerate(current_states_dict.keys()):\n",
    "                # There are 5 initial (shared) parameters from embeddings in each BERT model\n",
    "                if index < 5 and 'embeddings' in param:\n",
    "                    current_states_dict[param] = all_states_dict[param]\n",
    "                # There are 16 parameters for each of the K pretrained BERT layers (16 x K params)\n",
    "                elif index >= 5 and 'pooler' not in param:\n",
    "                    current_states_dict[param] = list(all_states_dict.values())[align:][index-5]\n",
    "                # There are 2 parameters for the pooling layer at the end in each BERT model\n",
    "                else:\n",
    "                    if not reinitialize_pooler_parameters:\n",
    "                        current_states_dict[param] = all_states_dict[param]\n",
    "                    else:\n",
    "                        if 'weight' in param:\n",
    "                            current_states_dict[param] = torch.ones(self.config.hidden_size,\n",
    "                                                                    self.config.hidden_size)\n",
    "                        elif 'bias' in param:\n",
    "                            current_states_dict[param] = torch.zeros(self.config.hidden_size)\n",
    "\n",
    "        del all_states_dict\n",
    "        self.bert.load_state_dict(current_states_dict)\n",
    "\n",
    "        logging.info('Loaded %d learnable parameters from pretrained BERT model with %d layer(s)' %\n",
    "                     (len(list(self.bert.parameters())), num_pretrained_bert_layers))\n",
    "\n",
    "        # Number of input hidden dimensions from the final BERT layer, as input to other layers\n",
    "        input_hidden_dimension = None\n",
    "        if concatenate_hidden_states:\n",
    "            input_hidden_dimension = (num_pretrained_bert_layers + 1) * self.config.hidden_size\n",
    "        else:\n",
    "            input_hidden_dimension = self.config.hidden_size\n",
    "\n",
    "        self.flatten_sequence_length = lambda t: t.view(-1,\n",
    "                                                        self.config.max_position_embeddings *\n",
    "                                                        input_hidden_dimension)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        if self.num_recurrent_layers > 0:\n",
    "            self.lstm = nn.LSTM(input_size=input_hidden_dimension,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_recurrent_layers,\n",
    "                                bidirectional=use_bidirectional,\n",
    "                                batch_first=True)\n",
    "            self.clf = nn.Linear(in_features=hidden_size*2 if use_bidirectional else hidden_size,\n",
    "                                 out_features=num_classes)\n",
    "        else:\n",
    "            if aggregate_on_cls_token:\n",
    "                self.clf = nn.Linear(in_features=input_hidden_dimension,\n",
    "                                     out_features=num_classes)\n",
    "            else:\n",
    "                self.clf = nn.Linear(in_features=max_tokenization_length * input_hidden_dimension,\n",
    "                                     out_features=num_classes)\n",
    "\n",
    "    def get_tokenizer(self):\n",
    "        \"\"\"Function to easily access the BERT tokenizer\"\"\"\n",
    "        return self.tokenizer\n",
    "\n",
    "    def get_bert_attention(self, raw_sentence, header, device):\n",
    "        \"\"\"Function for getting the multi-head self-attention output from pretrained BERT\"\"\"\n",
    "        x = tokenize_and_encode(text=raw_sentence,                             \n",
    "                                header=header,\n",
    "                                tokenizer=self.get_tokenizer(),\n",
    "                                max_tokenization_length=self.config.max_position_embeddings,\n",
    "                                truncation_method='head-only')\n",
    "        x = torch.tensor(data=x, device=device)\n",
    "        x = x.unsqueeze(dim=1).view(1, -1)                                     \n",
    "\n",
    "        token_type_ids, attention_mask = get_features(input_ids=x,\n",
    "                                                      tokenizer=self.get_tokenizer(),\n",
    "                                                      device=device)\n",
    "        bert_outputs = self.bert(input_ids=x,                                  \n",
    "                                 token_type_ids=token_type_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 position_ids=None,\n",
    "                                 head_mask=None)\n",
    "        attention_outputs = bert_outputs[3]                                    \n",
    "        return attention_outputs\n",
    "\n",
    "    def predict(self, text, header_id):\n",
    "        header = targets[target_idx.index(header_id)]\n",
    "        stance_input_ids = tokenize_and_encode(text, \n",
    "                                               self.get_tokenizer(), \n",
    "                                               header, \n",
    "                                               apply_cleaning=APPLY_CLEANING,\n",
    "                                               max_tokenization_length=MAX_TOKENIZATION_LENGTH,\n",
    "                                               truncation_method=TRUNCATION_METHOD)\n",
    "        stance_input_ids = torch.from_numpy(np.array(stance_input_ids).reshape(1, -1)).long().to(DEVICE)\n",
    "        stance_token_id, stance_attention_mask = get_features(stance_input_ids,\n",
    "                                                              tokenizer=self.get_tokenizer(),\n",
    "                                                              device=DEVICE)\n",
    "        return self.forward(input_ids=stance_input_ids,\n",
    "                            token_type_ids=stance_token_id,\n",
    "                            attention_mask=stance_attention_mask)\n",
    "  \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None,     \n",
    "                position_ids=None, head_mask=None):\n",
    "        \"\"\"Function implementing a forward pass of the model\"\"\"\n",
    "        bert_outputs = self.bert(input_ids=input_ids,\n",
    "                                 token_type_ids=token_type_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 position_ids=position_ids,\n",
    "                                 head_mask=head_mask)\n",
    "        sequence_output = bert_outputs[0]                                      \n",
    "        pooled_output = bert_outputs[1]                                        \n",
    "        hidden_outputs = bert_outputs[2]                                       \n",
    "        attention_outputs = bert_outputs[3]                                    \n",
    "\n",
    "        if self.concatenate_hidden_states:\n",
    "            sequence_output = torch.cat(hidden_outputs, dim=-1)               \n",
    "\n",
    "        if self.num_recurrent_layers > 0:\n",
    "            if self.use_gpu:\n",
    "                h0 = Variable(torch.zeros(self.num_recurrent_layers * 2        \n",
    "                                          if self.use_bidirectional else self.num_recurrent_layers,\n",
    "                                          input_ids.shape[0],\n",
    "                                          self.hidden_size)).cuda()\n",
    "                c0 = Variable(torch.zeros(self.num_recurrent_layers * 2        \n",
    "                                          if self.use_bidirectional else self.num_recurrent_layers,\n",
    "                                          input_ids.shape[0],\n",
    "                                          self.hidden_size)).cuda()\n",
    "            else:\n",
    "                h0 = Variable(torch.zeros(self.num_recurrent_layers * 2        \n",
    "                                          if self.use_bidirectional else self.num_recurrent_layers,\n",
    "                                          input_ids.shape[0],\n",
    "                                          self.hidden_size))\n",
    "                c0 = Variable(torch.zeros(self.num_recurrent_layers * 2        \n",
    "                                          if self.use_bidirectional else self.num_recurrent_layers,\n",
    "                                          input_ids.shape[0],\n",
    "                                          self.hidden_size))\n",
    "\n",
    "            lstm_output = self.lstm(sequence_output, (h0, c0))                 )\n",
    "            sequence_output, _ = lstm_output\n",
    "\n",
    "            last_timesteps = []\n",
    "            for i in range(len(attention_mask)):\n",
    "                last_timesteps.append(\n",
    "                    attention_mask[i].tolist().index(0)\n",
    "                    if 0 in attention_mask[i].tolist() else self.tokenizer.max_len - 1\n",
    "                )\n",
    "\n",
    "            if self.use_gpu:\n",
    "                last_timesteps = torch.tensor(data=last_timesteps).cuda()      \n",
    "            else:\n",
    "                last_timesteps = torch.tensor(data=last_timesteps)             \n",
    "            relative_hidden_size = self.hidden_size*2 if self.use_bidirectional else self.hidden_size\n",
    "            last_timesteps = last_timesteps.repeat(1, relative_hidden_size)    \n",
    "            last_timesteps = last_timesteps.view(-1, 1, relative_hidden_size)  \n",
    "            pooled_sequence_output = sequence_output.gather(                   \n",
    "                dim=1,\n",
    "                index=last_timesteps\n",
    "            ).squeeze()\n",
    "\n",
    "            pooled_sequence_output = self.dropout(pooled_sequence_output)      \n",
    "            logits = self.clf(pooled_sequence_output)                          \n",
    "        else:\n",
    "            if not self.aggregate_on_cls_token:\n",
    "                pooled_output = self.flatten_sequence_length(sequence_output)  \n",
    "\n",
    "            pooled_output = self.dropout(pooled_output)                        \n",
    "            logits = self.clf(pooled_output)                                  \n",
    "\n",
    "        return logits                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxCTvXjTgG59"
   },
   "outputs": [],
   "source": [
    "model = FineTunedBert(pretrained_model_name=PRETRAINED_MODEL_NAME,\n",
    "                      vocab_file=\"drive/MyDrive/TwitterProject/data/vocabulary.txt\",\n",
    "                      num_pretrained_bert_layers=NUM_PRETRAINED_BERT_LAYERS,\n",
    "                      max_tokenization_length=MAX_TOKENIZATION_LENGTH,\n",
    "                      num_classes=NUM_CLASSES,\n",
    "                      top_down=TOP_DOWN,\n",
    "                      num_recurrent_layers=NUM_RECURRENT_LAYERS,\n",
    "                      use_bidirectional=USE_BIDIRECTIONAL,\n",
    "                      hidden_size=HIDDEN_SIZE,\n",
    "                      reinitialize_pooler_parameters=REINITIALIZE_POOLER_PARAMETERS,\n",
    "                      dropout_rate=DROPOUT_RATE,\n",
    "                      aggregate_on_cls_token=AGGREGATE_ON_CLS_TOKEN,\n",
    "                      concatenate_hidden_states=CONCATENATE_HIDDEN_STATES,\n",
    "                      use_gpu=True if torch.cuda.is_available() else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PI9Tu71piwDn"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_encode(text, tokenizer, header='', apply_cleaning=False, max_tokenization_length=512,\n",
    "                        truncation_method='head-only', split_head_density=0.5):\n",
    "    \"\"\"\n",
    "    Function to tokenize & encode a given text.\n",
    "    @param (str) text: a sequence of words to be tokenized in raw string format\n",
    "    @param (pytorch_transformers.BertTokenizer) tokenizer: tokenizer with pre-figured mappings\n",
    "    @param (bool) apply_cleaning: whether or not to perform common cleaning operations on texts;\n",
    "           note that enabling only makes sense if language of the task is English (default: False)\n",
    "    @param (int) max_tokenization_length: maximum number of positional embeddings, or the sequence\n",
    "           length of an example that will be fed to BERT model (default: 512)\n",
    "    @param (str) truncation_method: method that will be applied in case the text exceeds\n",
    "           @max_tokenization_length; currently implemented methods include 'head-only', 'tail-only',\n",
    "           and 'head+tail' (default: 'head-only')\n",
    "    @param (float) split_head_density: weight on head when splitting between head and tail, only\n",
    "           applicable if @truncation_method='head+tail' (default: 0.5)\n",
    "    @return (list) input_ids: the encoded integer indexes of the given text; note that\n",
    "            get_data_iterators() function converts this to a Tensor under the hood\n",
    "    \"\"\"\n",
    "    if apply_cleaning:\n",
    "        text = clean_text(text=text)\n",
    "\n",
    "    # Tokenize and encode\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokenized_header = tokenizer.tokenize(header)\n",
    "    header_ids = tokenizer.convert_tokens_to_ids(tokenized_header)\n",
    "\n",
    "    text_tokenization_length = max_tokenization_length - 3 - len(header_ids)\n",
    "    if len(input_ids) > text_tokenization_length:\n",
    "        if truncation_method == 'head-only':\n",
    "            input_ids = input_ids[:text_tokenization_length]\n",
    "        elif truncation_method == 'tail-only':\n",
    "            input_ids = input_ids[-text_tokenization_length:]\n",
    "        elif truncation_method == 'head+tail':\n",
    "            head_tokenization_length = int(text_tokenization_length * split_head_density)\n",
    "            tail_tokenization_length = text_tokenization_length - head_tokenization_length\n",
    "            input_head_ids = input_ids[:head_tokenization_length]\n",
    "            input_tail_ids = input_ids[-tail_tokenization_length:]\n",
    "            input_ids = input_head_ids + input_tail_ids  \n",
    "\n",
    "    cls_id = tokenizer.convert_tokens_to_ids('[CLS]')\n",
    "    sep_id = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "    input_ids = [cls_id] + header_ids + [sep_id] + input_ids + [sep_id]\n",
    "\n",
    "\n",
    "    pad_id = tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "    if len(input_ids) < max_tokenization_length:\n",
    "        padding_length = max_tokenization_length - len(input_ids)\n",
    "        input_ids = input_ids + ([pad_id] * padding_length)\n",
    "\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "def get_features(input_ids, tokenizer, device):\n",
    "    token_type_ids, attention_mask = [], []\n",
    "\n",
    "    for input_ids_example in input_ids:\n",
    "        input_ids_example = input_ids_example.squeeze().tolist()\n",
    "        if input_ids.shape[0] == 1:\n",
    "            input_ids_example = input_ids.squeeze().tolist()\n",
    "        padding_token_id = tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "        padding_length = input_ids_example.count(padding_token_id)\n",
    "        text_length = len(input_ids_example) - padding_length\n",
    "\n",
    "        token_type_ids_example = [0] * len(input_ids_example)\n",
    "        attention_mask_example = ([1] * text_length) + ([0] * padding_length)\n",
    "\n",
    "        assert len(token_type_ids_example) == len(input_ids_example)\n",
    "        assert len(attention_mask_example) == len(input_ids_example)\n",
    "        token_type_ids.append(token_type_ids_example)\n",
    "        attention_mask.append(attention_mask_example)\n",
    "\n",
    "    token_type_ids = torch.tensor(data=token_type_ids, device=device)\n",
    "    attention_mask = torch.tensor(data=attention_mask, device=device)\n",
    "    return token_type_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0TlBFBBhfsO"
   },
   "outputs": [],
   "source": [
    "#Dataset\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, input_directory, tokenizer, apply_cleaning, max_tokenization_length,\n",
    "                 truncation_method='head-only', split_head_density=0.5, device='cpu'):\n",
    "        super(TweetDataset).__init__()\n",
    "        # agree folder\n",
    "        self.agree_path = os.path.join(input_directory, 'agree')\n",
    "        self.agree_files = [f for f in os.listdir(self.agree_path)\n",
    "                               if os.path.isfile(os.path.join(self.agree_path, f))]\n",
    "        self.num_agree_examples = len(self.agree_files)\n",
    "        self.agree_label = 0\n",
    "        \n",
    "        self.disagree_path = os.path.join(input_directory, 'disagree')\n",
    "        self.disagree_files = [f for f in os.listdir(self.disagree_path)\n",
    "                               if os.path.isfile(os.path.join(self.disagree_path, f))]\n",
    "        self.num_disagree_examples = len(self.disagree_files)\n",
    "        self.disagree_label = 1\n",
    "\n",
    "        self.nostance_path = os.path.join(input_directory, 'no_stance')\n",
    "        self.nostance_files = [f for f in os.listdir(self.nostance_path)\n",
    "                               if os.path.isfile(os.path.join(self.nostance_path, f))]\n",
    "        self.num_nostance_examples = len(self.nostance_files)\n",
    "        self.nostance_label = 2\n",
    "\n",
    "        self.notrelevant_path = os.path.join(input_directory, 'not_relevant')\n",
    "        self.notrelevant_files = [f for f in os.listdir(self.notrelevant_path)\n",
    "                               if os.path.isfile(os.path.join(self.notrelevant_path, f))]\n",
    "        self.num_notrelevant_examples = len(self.notrelevant_files)\n",
    "        self.notrelevant_label = 3\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.apply_cleaning = apply_cleaning\n",
    "        self.max_tokenization_length = max_tokenization_length\n",
    "        self.truncation_method = truncation_method\n",
    "        self.split_head_density = split_head_density\n",
    "        self.device = device\n",
    "\n",
    "        self.pre_tokenize_and_encode_examples()\n",
    "\n",
    "    def pre_tokenize_and_encode_examples(self):\n",
    "        self.__pre_tokenize_and_encode_examples__(self.agree_path, self.agree_files)\n",
    "        self.__pre_tokenize_and_encode_examples__(self.disagree_path, self.disagree_files)\n",
    "        self.__pre_tokenize_and_encode_examples__(self.nostance_path, self.nostance_files)\n",
    "        self.__pre_tokenize_and_encode_examples__(self.notrelevant_path, self.notrelevant_files)\n",
    "\n",
    "    def __pre_tokenize_and_encode_examples__(self, path, files):\n",
    "        if not os.path.exists(os.path.join(path, 'tokenized_and_encoded')):\n",
    "            os.mkdir(os.path.join(path, 'tokenized_and_encoded'))\n",
    "\n",
    "            for i in trange(len(files), desc='Tokenizing & Encoding {} Tweets'.format(path),\n",
    "                            leave=True):\n",
    "                file = files[i]\n",
    "                m_id = int(file.split('_')[0])\n",
    "                idx = target_idx.index(m_id)\n",
    "                target = targets[idx]\n",
    "                with open(os.path.join(path, file), mode='r', encoding='utf8') as f:\n",
    "                    example = f.read()\n",
    "                example = re.sub(r'<br />', '', example)\n",
    "                example = example.lstrip().rstrip()\n",
    "                example = re.sub(' +', ' ', example)\n",
    "                example = tokenize_and_encode(text=example,\n",
    "                                              header=target,\n",
    "                                              tokenizer=self.tokenizer,\n",
    "                                              apply_cleaning=self.apply_cleaning,\n",
    "                                              max_tokenization_length=self.max_tokenization_length,\n",
    "                                              truncation_method=self.truncation_method,\n",
    "                                              split_head_density=self.split_head_density)\n",
    "\n",
    "                with open(os.path.join(path, 'tokenized_and_encoded', file), mode='wb') as f:\n",
    "                    pickle.dump(obj=example, file=f)\n",
    "        else:\n",
    "            logging.warning('Tokenized {} directory already exists!'.format(path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.agree_files) + len(self.disagree_files) + len(self.nostance_files) + len(self.notrelevant_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # agree\n",
    "        if index < self.num_agree_examples:\n",
    "            file = self.agree_files[index]\n",
    "            label = torch.tensor(data=self.agree_label, dtype=torch.long).to(self.device)\n",
    "            with open(os.path.join(self.agree_path, 'tokenized_and_encoded', file), mode='rb') as f:\n",
    "                example = pickle.load(file=f)\n",
    "        elif index < self.num_agree_examples + self.num_disagree_examples:\n",
    "            file = self.disagree_files[index - self.num_agree_examples]\n",
    "            label = torch.tensor(data=self.disagree_label, dtype=torch.long).to(self.device)\n",
    "            with open(os.path.join(self.disagree_path, 'tokenized_and_encoded', file), mode='rb') as f:\n",
    "                example = pickle.load(file=f)\n",
    "        elif index < self.num_agree_examples + self.num_disagree_examples + self.num_nostance_examples:\n",
    "            file = self.nostance_files[index - self.num_agree_examples - self.num_disagree_examples]\n",
    "            label = torch.tensor(data=self.nostance_label, dtype=torch.long).to(self.device)\n",
    "            with open(os.path.join(self.nostance_path, 'tokenized_and_encoded', file), mode='rb') as f:\n",
    "                example = pickle.load(file=f)\n",
    "        elif index < self.num_agree_examples + self.num_disagree_examples + self.num_nostance_examples + self.num_notrelevant_examples:\n",
    "            file = self.notrelevant_files[index - self.num_agree_examples - self.num_disagree_examples - self.num_nostance_examples]\n",
    "            label = torch.tensor(data=self.notrelevant_label, dtype=torch.long).to(self.device)\n",
    "            with open(os.path.join(self.notrelevant_path, 'tokenized_and_encoded', file), mode='rb') as f:\n",
    "                example = pickle.load(file=f)\n",
    "        else:\n",
    "            raise ValueError('Out of range index while accessing dataset')\n",
    "\n",
    "        return torch.from_numpy(np.array(example)).long().to(self.device), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iycmVn1g7sI",
    "outputId": "fd2f23d4-d813-4890-f4ec-371e85cc2eef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/train/agree directory already exists!\n",
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/train/disagree directory already exists!\n",
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/train/no_stance directory already exists!\n",
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/train/not_relevant directory already exists!\n",
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/test/agree directory already exists!\n",
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/test/disagree directory already exists!\n",
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/test/no_stance directory already exists!\n",
      "WARNING:root:Tokenized drive/MyDrive/CS 6320 Project/data/test/not_relevant directory already exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TweetDataset object at 0x7fb41e37bf90>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TweetDataset(input_directory=\"drive/MyDrive/TwitterProject/data/train\",\n",
    "                            tokenizer=model.get_tokenizer(),\n",
    "                            apply_cleaning=True,\n",
    "                            max_tokenization_length=MAX_TOKENIZATION_LENGTH,\n",
    "                            truncation_method='head-only',\n",
    "                            device=DEVICE)\n",
    "\n",
    "test_dataset = TweetDataset(input_directory=\"drive/MyDrive/CS 6320 Project/data/test\",\n",
    "                           tokenizer=model.get_tokenizer(),\n",
    "                           apply_cleaning=True,\n",
    "                           max_tokenization_length=MAX_TOKENIZATION_LENGTH,\n",
    "                           truncation_method='head-only',\n",
    "                           device=DEVICE)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNUq8sYYk5ut"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "bert_learning_rate = BERT_LEARNING_RATE\n",
    "custom_learning_rate = CUSTOM_LEARNING_RATE\n",
    "bert_identifiers = ['embeddings']\n",
    "no_weight_decay_identifiers = ['bias', 'LayerNorm.weight']\n",
    "grouped_model_parameters = [\n",
    "        {'params': [param for name, param in model.named_parameters()\n",
    "                    if any(identifier in name for identifier in bert_identifiers) and\n",
    "                    not any(identifier_ in name for identifier_ in no_weight_decay_identifiers)],\n",
    "          'lr': bert_learning_rate,\n",
    "          'betas': (0.9, 0.999),\n",
    "          'weight_decay': 0.01,\n",
    "          'eps': 1e-8},\n",
    "        {'params': [param for name, param in model.named_parameters()\n",
    "                    if any(identifier in name for identifier in bert_identifiers) and\n",
    "                    any(identifier_ in name for identifier_ in no_weight_decay_identifiers)],\n",
    "          'lr': bert_learning_rate,\n",
    "          'betas': (0.9, 0.999),\n",
    "          'weight_decay': 0.0,\n",
    "          'eps': 1e-8},\n",
    "        {'params': [param for name, param in model.named_parameters()\n",
    "                    if not any(identifier in name for identifier in bert_identifiers)],\n",
    "          'lr': custom_learning_rate,\n",
    "          'betas': (0.9, 0.999),\n",
    "          'weight_decay': 0.0,\n",
    "          'eps': 1e-8}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(grouped_model_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSLq8zcwjAkU"
   },
   "outputs": [],
   "source": [
    "model, criterion = model.to(DEVICE), criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPKHP0jqjnnz"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(y_pred, y_true):\n",
    "    y_pred_max = torch.argmax(y_pred, dim=-1)\n",
    "    correct_pred = (y_pred_max == y_true).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def train(model, iterator, criterion, optimizer, device, include_bert_masks=True):\n",
    "    epoch_loss, epoch_acc = 0.0, 0.0\n",
    "\n",
    "    for batch in iterator:\n",
    "        input_ids, labels = batch\n",
    "        token_type_ids, attention_mask = get_features(input_ids=input_ids,\n",
    "                                                      tokenizer=model.get_tokenizer(),\n",
    "                                                      device=device)\n",
    "        optimizer.zero_grad()\n",
    "        if include_bert_masks:\n",
    "            predictions = model(input_ids=input_ids,\n",
    "                                token_type_ids=token_type_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "        else:\n",
    "            predictions = model(input_ids=input_ids,header_ids=header_ids)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "        acc = binary_accuracy(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def test(model, iterator, criterion, device, include_bert_masks=True):\n",
    "    epoch_loss, epoch_acc = 0.0, 0.0\n",
    "    confusion = [[0 for _ in range(0, 4)] for _ in range(0, 4)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            input_ids, labels = batch\n",
    "            token_type_ids, attention_mask = get_features(input_ids=input_ids,\n",
    "                                                          tokenizer=model.get_tokenizer(),\n",
    "                                                          device=device)\n",
    "            if include_bert_masks:\n",
    "                predictions = model(input_ids=input_ids,\n",
    "                                    token_type_ids=token_type_ids,\n",
    "                                    attention_mask=attention_mask)\n",
    "            else:\n",
    "                predictions = model(input_ids=input_ids)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = binary_accuracy(predictions, labels)\n",
    "            y_pred_max = torch.argmax(predictions, dim=-1)\n",
    "            confusion += confusion_matrix(labels.cpu().detach().numpy(),y_pred_max.cpu().detach().numpy(),labels=[0,1,2,3])\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), confusion\n",
    "\n",
    "\n",
    "def get_attention_nth_layer_mth_head_kth_token(attention_outputs, n, m, k, average_heads=False):\n",
    "    if average_heads is True and m is not None:\n",
    "        logging.warning(\"Argument passed for param @m will be ignored because of head averaging.\")\n",
    "\n",
    "    attention_outputs_concatenated = torch.cat(attention_outputs, dim=0)       \n",
    "    attention_outputs = attention_outputs_concatenated.data[n, :, :, :]        \n",
    "\n",
    "    attention_outputs = attention_outputs[:, k, :]                             \n",
    "\n",
    "    if average_heads:\n",
    "        attention_outputs = torch.sum(attention_outputs, dim=0)               \n",
    "        num_attention_heads = attention_outputs_concatenated.shape[1]\n",
    "        attention_outputs /= num_attention_heads\n",
    "    else:\n",
    "        attention_outputs = attention_outputs[m, :]                           \n",
    "\n",
    "    return attention_outputs\n",
    "\n",
    "\n",
    "def get_attention_average_first_layer(attention_outputs):\n",
    "    return get_attention_nth_layer_mth_head_kth_token(attention_outputs=attention_outputs,\n",
    "                                                      n=0, m=None, k=0,\n",
    "                                                      average_heads=True)\n",
    "\n",
    "\n",
    "def get_attention_average_last_layer(attention_outputs):\n",
    "    return get_attention_nth_layer_mth_head_kth_token(attention_outputs=attention_outputs,\n",
    "                                                      n=-1, m=None, k=0,\n",
    "                                                      average_heads=True)\n",
    "\n",
    "\n",
    "def get_normalized_attention(model, raw_sentence, method='last_layer_heads_average',\n",
    "                             n=None, m=None, k=None, exclude_special_tokens=True,\n",
    "                             normalization_method='normal', device='cpu'):\n",
    "    if None in [n, m, k] and method == 'custom':\n",
    "        raise ValueError(\"Must pass integer argument for params @n, @m, and @k \" +\n",
    "                         \"if method is 'nth_layer_mth_head_kth_token'\")\n",
    "    elif None not in [n, m, k] and method != 'custom':\n",
    "        logging.warning(\"Arguments passed for params @n, @m, or @k will be ignored. \" +\n",
    "                        \"Specify @method as 'nth_layer_mth_head_kth_token' to make them effective.\")\n",
    "\n",
    "    if '[CLS]' not in raw_sentence and '[SEP]' not in raw_sentence:\n",
    "        tokenized_text = ['[CLS]'] + model.get_tokenizer().tokenize(raw_sentence) + ['[SEP]']\n",
    "    else:\n",
    "        tokenized_text = model.get_tokenizer().tokenize(raw_sentence)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        attention_outputs = model.get_bert_attention(raw_sentence=raw_sentence, device=device)\n",
    "\n",
    "    attention_weights = None\n",
    "    if method == 'first_layer_heads_average':\n",
    "        attention_weights = get_attention_nth_layer_mth_head_kth_token(\n",
    "            attention_outputs=attention_outputs,\n",
    "            n=0, m=None, k=0,\n",
    "            average_heads=True\n",
    "        )\n",
    "    elif method == 'last_layer_heads_average':\n",
    "        attention_weights = get_attention_nth_layer_mth_head_kth_token(\n",
    "            attention_outputs=attention_outputs,\n",
    "            n=-1, m=None, k=0,\n",
    "            average_heads=True\n",
    "        )\n",
    "    elif method == 'nth_layer_heads_average':\n",
    "        attention_weights = get_attention_nth_layer_mth_head_kth_token(\n",
    "            attention_outputs=attention_outputs,\n",
    "            n=n, m=None, k=0,\n",
    "            average_heads=True\n",
    "        )\n",
    "    elif method == 'nth_layer_mth_head':\n",
    "        attention_weights = get_attention_nth_layer_mth_head_kth_token( \n",
    "            attention_outputs=attention_outputs,\n",
    "            n=n, m=m, k=0,\n",
    "            average_heads=False\n",
    "        )\n",
    "    elif method == 'custom':\n",
    "        attention_weights = get_attention_nth_layer_mth_head_kth_token(\n",
    "            attention_outputs=attention_outputs,\n",
    "            n=n, m=m, k=k,\n",
    "            average_heads=False\n",
    "        )\n",
    "\n",
    "    if exclude_special_tokens:\n",
    "        tokenized_text, attention_weights = tokenized_text[1:-1], attention_weights[1:-1]\n",
    "\n",
    "    if normalization_method == 'min-max':\n",
    "        max_weight, min_weight = attention_weights.max(), attention_weights.min()\n",
    "        attention_weights = (attention_weights - min_weight) / (max_weight - min_weight)\n",
    "\n",
    "    elif normalization_method == 'normal':\n",
    "        mu, std = attention_weights.mean(), attention_weights.std()\n",
    "        attention_weights = (attention_weights - mu) / std\n",
    "\n",
    "    attention_weights = attention_weights.data\n",
    "\n",
    "    tokens_and_weights = []\n",
    "    for index, token in enumerate(tokenized_text):\n",
    "        tokens_and_weights.append((token, attention_weights[index].item()))\n",
    "\n",
    "    return tokens_and_weights\n",
    "\n",
    "\n",
    "def get_delta_attention(tokens_and_weights_pre, tokens_and_weights_post):\n",
    "    tokens_and_weights_delta = []\n",
    "    for i, token_and_weight in enumerate(tokens_and_weights_pre):\n",
    "        token,  = token_and_weight[0],\n",
    "        assert token == tokens_and_weights_post[i][0]\n",
    "\n",
    "        pre_weight = token_and_weight[1]\n",
    "        post_weight = tokens_and_weights_post[i][1]\n",
    "\n",
    "        tokens_and_weights_delta.append((token, post_weight - pre_weight))\n",
    "\n",
    "    return tokens_and_weights_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILdVyzhFjbmr",
    "outputId": "de904368-83bb-4c43-af55-6a02ffbebe2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH NO: 1\n",
      "\tTrain Loss: 1.013 | Train Accuracy: 58.03%\n",
      "\tTest Loss:  0.979 | Test Accuracy:  62.50%\n",
      "\tTest confusion:\n",
      "[[41 10  0 11]\n",
      " [21  7  0  1]\n",
      " [19  4  0 16]\n",
      " [ 9  5  0 55]]\n",
      "EPOCH NO: 2\n",
      "\tTrain Loss: 0.979 | Train Accuracy: 58.78%\n",
      "\tTest Loss:  0.935 | Test Accuracy:  64.84%\n",
      "\tTest confusion:\n",
      "[[52  8  0  2]\n",
      " [23  6  0  0]\n",
      " [25  4  1  9]\n",
      " [16  3  0 50]]\n",
      "EPOCH NO: 3\n",
      "\tTrain Loss: 0.916 | Train Accuracy: 62.07%\n",
      "\tTest Loss:  0.846 | Test Accuracy:  67.19%\n",
      "\tTest confusion:\n",
      "[[52  6  0  4]\n",
      " [22  7  0  0]\n",
      " [24  4  1 10]\n",
      " [14  0  0 55]]\n",
      "EPOCH NO: 4\n",
      "\tTrain Loss: 0.848 | Train Accuracy: 65.25%\n",
      "\tTest Loss:  0.867 | Test Accuracy:  67.58%\n",
      "\tTest confusion:\n",
      "[[41 11  1  9]\n",
      " [17 10  1  1]\n",
      " [18  5  1 15]\n",
      " [ 5  0  0 64]]\n",
      "EPOCH NO: 5\n",
      "\tTrain Loss: 0.820 | Train Accuracy: 66.97%\n",
      "\tTest Loss:  0.868 | Test Accuracy:  66.41%\n",
      "\tTest confusion:\n",
      "[[37 15  2  8]\n",
      " [13 15  1  0]\n",
      " [18  8  1 12]\n",
      " [ 8  1  0 60]]\n",
      "EPOCH NO: 6\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "worst_test_count = 0\n",
    "prev_test_loss = 0\n",
    "epoch_count = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_count += 1\n",
    "    print(\"EPOCH NO: %d\" % (epoch + 1))\n",
    "    train_loss, train_acc = train(model=model,\n",
    "                                  iterator=train_loader,\n",
    "                                  criterion=criterion,\n",
    "                                  optimizer=optimizer,\n",
    "                                  device=DEVICE,\n",
    "                                  include_bert_masks=True)\n",
    "    \n",
    "    test_loss, test_acc, confusion = test(model=model,\n",
    "                              iterator=test_loader,\n",
    "                              criterion=criterion,\n",
    "                              device=DEVICE,\n",
    "                              include_bert_masks=True)\n",
    "    \n",
    "    if test_loss > prev_test_loss:\n",
    "        worst_test_count += 1\n",
    "    if worst_test_count == 4:\n",
    "        break\n",
    "    prev_test_loss = test_loss\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'drive/MyDrive/TwitterProject/saved_models/BERT-stance-detection-drop-0.4.pt')\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Accuracy: {train_acc * 100:.2f}%')\n",
    "    print(f'\\tTest Loss:  {test_loss:.3f} | Test Accuracy:  {test_acc * 100:.2f}%')\n",
    "    print(f'\\tTest confusion:\\n{confusion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "-z4g41N8_1bO",
    "outputId": "46e2d8fe-f2d1-4298-deb9-92ffc710bfe8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5zOdf7/8cfTOaEDKhmnNpLQYFDZpOOiQlLRbOhAdD5spXSwyrf9bna3n+/qoJNqp9TWZlWsDli1nQxJKUqiyJaUQ1Gh1++P92e4jJkxF9c1nzm87rfbdZvr8/4crtfnw1yveb/fn8/7LTPDOeecK65KcQfgnHOubPHE4ZxzLimeOJxzziXFE4dzzrmkeOJwzjmXFE8czjnnkuKJw8VO0jRJg1K9bZwkLZN0UhqOa5IOjd7fJ+mW4my7G5+TLeml3Y2ziON2k7Qi1cd1JatK3AG4sknS9wmLNYGfgK3R8sVmllPcY5lZj3RsW96Z2bBUHEdSU+AzoKqZbYmOnQMU+9/QVSyeONxuMbNaee8lLQMuMrNX8m8nqUrel5FzrnzwpiqXUnlNEZJukPRf4BFJ+0l6QdJqSd9F7zMS9pkl6aLo/WBJr0saG237maQeu7ltM0mzJW2Q9Iqk8ZL+VkjcxYnxdkn/iY73kqR6CevPk7Rc0hpJI4u4Pp0l/VdS5YSyMyQtiN53kvSmpLWSVkn6q6RqhRxroqQ7Epavi/b5UtIF+bY9VdK7ktZL+kLSqITVs6OfayV9L+novGubsP8xkuZIWhf9PKa416Yokg6P9l8raaGkXgnrekr6MDrmSkm/i8rrRf8+ayV9K+k1Sf5dVoL8Yrt0OAjYH2gCDCX8P3skWm4MbAL+WsT+nYHFQD3gj8BDkrQb2z4BvAPUBUYB5xXxmcWJ8VzgfOAAoBqQ90XWCrg3Ov7B0edlUAAzexv4ATgh33GfiN5vBa6Ozudo4ETgkiLiJoqhexTPyUBzIH//yg/AQGBf4FRguKQ+0bqu0c99zayWmb2Z79j7Ay8C46Jz+zPwoqS6+c5hp2uzi5irAs8DL0X7XQ7kSDos2uQhQrNnbaA1MCMqvxZYAdQHDgRuAnzspBLkicOlwy/AbWb2k5ltMrM1ZvasmW00sw3AGOC4IvZfbmYPmNlW4FGgAeELotjbSmoMdARuNbOfzex1YEphH1jMGB8xs4/NbBPwNJAZlfcDXjCz2Wb2E3BLdA0K8yQwAEBSbaBnVIaZzTWzt8xsi5ktA+4vII6CnB3F94GZ/UBIlInnN8vM3jezX8xsQfR5xTkuhETziZk9HsX1JLAIOD1hm8KuTVGOAmoBf4j+jWYALxBdG2Az0EpSHTP7zszmJZQ3AJqY2WYze8180L0S5YnDpcNqM/sxb0FSTUn3R0056wlNI/smNtfk89+8N2a2MXpbK8ltDwa+TSgD+KKwgIsZ438T3m9MiOngxGNHX9xrCvssQu2ir6TqQF9gnpktj+JoETXD/DeK438ItY9d2SEGYHm+8+ssaWbUFLcOGFbM4+Yde3m+suVAw4Tlwq7NLmM2s8Qkm3jcMwlJdbmkf0s6Oiq/C1gCvCRpqaQRxTsNlyqeOFw65P/r71rgMKCzmdVhe9NIYc1PqbAK2F9SzYSyRkVsvycxrko8dvSZdQvb2Mw+JHxB9mDHZioITV6LgOZRHDftTgyE5rZETxBqXI3MbB/gvoTj7uqv9S8JTXiJGgMrixHXro7bKF//xLbjmtkcM+tNaMaaTKjJYGYbzOxaMzsE6AVcI+nEPYzFJcEThysJtQl9Bmuj9vLb0v2B0V/wucAoSdWiv1ZPL2KXPYnxGeA0Sb+OOrJHs+vfrSeAKwkJ6u/54lgPfC+pJTC8mDE8DQyW1CpKXPnjr02ogf0oqRMhYeVZTWhaO6SQY08FWkg6V1IVSecArQjNSnvibULt5HpJVSV1I/wbTYr+zbIl7WNmmwnX5BcASadJOjTqy1pH6BcqqmnQpZgnDlcS7gb2Ar4B3gL+VUKfm03oYF4D3AE8RXjepCC7HaOZLQQuJSSDVcB3hM7bouT1Mcwws28Syn9H+FLfADwQxVycGKZF5zCD0IwzI98mlwCjJW0AbiX66z3adyOhT+c/0Z1KR+U79hrgNEKtbA1wPXBavriTZmY/ExJFD8J1vwcYaGaLok3OA5ZFTXbDCP+eEDr/XwG+B94E7jGzmXsSi0uOvE/JVRSSngIWmVnaazzOlWde43DllqSOkn4lqVJ0u2pvQlu5c24P+JPjrjw7CPgHoaN6BTDczN6NNyTnyj5vqnLOOZcUb6pyzjmXlArRVFWvXj1r2rRp3GE451yZMnfu3G/MrH7+8gqROJo2bUpubm7cYTjnXJkiKf+IAYA3VTnnnEuSJw7nnHNJ8cThnHMuKRWij8M5V/I2b97MihUr+PHHH3e9sYtVjRo1yMjIoGrVqsXa3hOHcy4tVqxYQe3atWnatCmFz8Pl4mZmrFmzhhUrVtCsWbNi7eNNVYXIyYGmTaFSpfAzJyfuiJwrW3788Ufq1q3rSaOUk0TdunWTqhl6jaMAOTkwdChsjKYAWr48LANkZxe+n3NuR540yoZk/528xlGAkSO3J408GzeGcuecq+g8cRTg88+TK3fOlS5r1qwhMzOTzMxMDjroIBo2bLht+eeffy5y39zcXK644opdfsYxxxyTklhnzZrFaaedlpJjlRRPHAVonH/SzV2UO+f2XCr7FevWrcv8+fOZP38+w4YN4+qrr962XK1aNbZs2VLovllZWYwbN26Xn/HGG2/sfoBlnCeOAowZAzVr7lhWs2Yod86lXl6/4vLlYLa9XzGVN6UMHjyYYcOG0blzZ66//nreeecdjj76aNq1a8cxxxzD4sWLgR1rAKNGjeKCCy6gW7duHHLIITsklFq1am3bvlu3bvTr14+WLVuSnZ1N3qjjU6dOpWXLlnTo0IErrrhilzWLb7/9lj59+tC2bVuOOuooFixYAMC///3vbTWmdu3asWHDBlatWkXXrl3JzMykdevWvPbaa6m7WLvgneMFyOsAHzkyNE81bhyShneMO5ceRfUrpvL3bsWKFbzxxhtUrlyZ9evX89prr1GlShVeeeUVbrrpJp599tmd9lm0aBEzZ85kw4YNHHbYYQwfPnyn5x3effddFi5cyMEHH0yXLl34z3/+Q1ZWFhdffDGzZ8+mWbNmDBgwYJfx3XbbbbRr147JkyczY8YMBg4cyPz58xk7dizjx4+nS5cufP/999SoUYMJEybwm9/8hpEjR7J161Y25r+AaeSJoxDZ2Z4onCspJdWveNZZZ1G5cmUA1q1bx6BBg/jkk0+QxObNmwvc59RTT6V69epUr16dAw44gK+++oqMjIwdtunUqdO2sszMTJYtW0atWrU45JBDtj0bMWDAACZMmFBkfK+//vq25HXCCSewZs0a1q9fT5cuXbjmmmvIzs6mb9++ZGRk0LFjRy644AI2b95Mnz59yMzM3KNrkwxvqnLOxa6k+hX33nvvbe9vueUWjj/+eD744AOef/75Qp9jqF69+rb3lStXLrB/pDjb7IkRI0bw4IMPsmnTJrp06cKiRYvo2rUrs2fPpmHDhgwePJjHHnsspZ9ZFE8czrnYxdGvuG7dOho2bAjAxIkTU378ww47jKVLl7Js2TIAnnrqqV3uc+yxx5ITdezMmjWLevXqUadOHT799FPatGnDDTfcQMeOHVm0aBHLly/nwAMPZMiQIVx00UXMmzcv5edQGE8czrnYZWfDhAnQpAlI4eeECeltLr7++uu58cYbadeuXcprCAB77bUX99xzD927d6dDhw7Url2bffbZp8h9Ro0axdy5c2nbti0jRozg0UcfBeDuu++mdevWtG3blqpVq9KjRw9mzZrFkUceSbt27Xjqqae48sorU34OhakQc45nZWWZT+TkXMn66KOPOPzww+MOI1bff/89tWrVwsy49NJLad68OVdffXXcYRWooH8vSXPNLCv/tl7jcM65NHnggQfIzMzkiCOOYN26dVx88cVxh5QSfleVc86lydVXX11qaxh7Iq01DkkPS/pa0geFrJekcZKWSFogqX3CukGSPolegxLKO0h6P9pnnHwUNeecK1HpbqqaCHQvYn0PoHn0GgrcCyBpf+A2oDPQCbhN0n7RPvcCQxL2K+r4zjnnUiyticPMZgPfFrFJb+AxC94C9pXUAPgN8LKZfWtm3wEvA92jdXXM7C0LvfqPAX3SeQ7OOed2FHfneEPgi4TlFVFZUeUrCijfiaShknIl5a5evTqlQTvnXEUWd+JIGzObYGZZZpZVv379uMNxzpWg448/nunTp+9QdvfddzN8+PBC9+nWrRt5t+337NmTtWvX7rTNqFGjGDt2bJGfPXnyZD788MNty7feeiuvvPJKMuEXqDQNvx534lgJNEpYzojKiirPKKDcOee2GTBgAJMmTdqhbNKkScUaaBDCqLb77rvvbn12/sQxevRoTjrppN06VmkVd+KYAgyM7q46ClhnZquA6cApkvaLOsVPAaZH69ZLOiq6m2og8M/YonfOlUr9+vXjxRdf3DZp07Jly/jyyy859thjGT58OFlZWRxxxBHcdtttBe7ftGlTvvnmGwDGjBlDixYt+PWvf71t6HUIz2h07NiRI488kjPPPJONGzfyxhtvMGXKFK677joyMzP59NNPGTx4MM888wwAr776Ku3ataNNmzZccMEF/PTTT9s+77bbbqN9+/a0adOGRYsWFXl+cQ+/ntbnOCQ9CXQD6klaQbhTqiqAmd0HTAV6AkuAjcD50bpvJd0OzIkONdrM8jrZLyHcrbUXMC16OedKsauugvnzU3vMzEy4++6C1+2///506tSJadOm0bt3byZNmsTZZ5+NJMaMGcP+++/P1q1bOfHEE1mwYAFt27Yt8Dhz585l0qRJzJ8/ny1bttC+fXs6dOgAQN++fRkyZAgAN998Mw899BCXX345vXr14rTTTqNfv347HOvHH39k8ODBvPrqq7Ro0YKBAwdy7733ctVVVwFQr1495s2bxz333MPYsWN58MEHCz33uIdfT/ddVQPMrIGZVTWzDDN7yMzui5IG0d1Ul5rZr8ysjZnlJuz7sJkdGr0eSSjPNbPW0T6XWUUYM8U5l7TE5qrEZqqnn36a9u3b065dOxYuXLhDs1J+r732GmeccQY1a9akTp069OrVa9u6Dz74gGOPPZY2bdqQk5PDwoULi4xn8eLFNGvWjBYtWgAwaNAgZs+evW193759AejQocO2gREL8/rrr3PeeecBBQ+/Pm7cONauXUuVKlXo2LEjjzzyCKNGjeL999+ndu3aRR67OPzJcedc2hVWM0in3r17c/XVVzNv3jw2btxIhw4d+Oyzzxg7dixz5sxhv/32Y/DgwYUOp74rgwcPZvLkyRx55JFMnDiRWbNm7VG8eUOz78mw7CNGjODUU09l6tSpdOnShenTp28bfv3FF19k8ODBXHPNNQwcOHCPYo27j8M559KiVq1aHH/88VxwwQXbahvr169n7733Zp999uGrr75i2rSiW7q7du3K5MmT2bRpExs2bOD555/ftm7Dhg00aNCAzZs3bxsKHaB27dps2LBhp2MddthhLFu2jCVLlgDw+OOPc9xxx+3WucU9/LrXOJxz5daAAQM444wztjVZ5Q1D3rJlSxo1akSXLl2K3L99+/acc845HHnkkRxwwAF07Nhx27rbb7+dzp07U79+fTp37rwtWfTv358hQ4Ywbty4bZ3iADVq1OCRRx7hrLPOYsuWLXTs2JFhw4bt1nnlzYXetm1batasucPw6zNnzqRSpUocccQR9OjRg0mTJnHXXXdRtWpVatWqlZIJn3xYdedcWviw6mWLD6vunHMubTxxOOecS4onDudc2lSEpvDyINl/J08czrm0qFGjBmvWrPHkUcqZGWvWrKFGjRrF3sfvqnLOpUVGRgYrVqzAR6cu/WrUqEFGRsauN4x44nDOpUXVqlVp1qxZ3GG4NPCmKuecc0nxxOGccy4pnjicc84lxROHS4mcHGjaFCpVCj8Thu5xzpUz3jlehHffhdq14dBD446kdMvJgaFDIW+Y/+XLwzJAdnZ8cTnn0sNrHEW4/HI44gi4+ebtX4puZyNH7nx9Nm4M5c658ietiUNSd0mLJS2RNKKA9U0kvSppgaRZkjKi8uMlzU94/SipT7RuoqTPEtZlpiv+v/8dzj4bxoyBww+HZ58Ff5ZpZ59/nly5c65sS1vikFQZGA/0AFoBAyS1yrfZWOAxM2sLjAbuBDCzmWaWaWaZwAmEaWVfStjvurz1ZpbiCSm3a9AAHn8cZs+GffeFfv3gN7+BhGmHHdC4cXLlzrmyLZ01jk7AEjNbamY/A5OA3vm2aQXMiN7PLGA9QD9gmpnF1lh07LEwdy6MGwfvvANt2sANN8D338cVUekyZgzUrLljWc2aodw5V/6kM3E0BL5IWF4RlSV6D+gbvT8DqC2pbr5t+gNP5isbEzVv/UVS9VQFXJQqVUKfx8cfw29/C3/8I7RsCU895c1X2dkwYQI0aQJS+DlhgneMO1dexd05/jvgOEnvAscBK4GteSslNQDaANMT9rkRaAl0BPYHbijowJKGSsqVlJvKsXIOOAAefhjeeAMOPBD694cTT4RdzFNf7mVnw7Jl8Msv4acnDefKr3QmjpVAo4TljKhsGzP70sz6mlk7YGRUtjZhk7OB58xsc8I+qyz4CXiE0CS2EzObYGZZZpZVv3791JxRgqOPDs1W994L8+fDkUfCNdfA+vUp/yjnnCtV0pk45gDNJTWTVI3Q5DQlcQNJ9STlxXAj8HC+YwwgXzNVVAtBkoA+wAdpiL1YKleGYcNC89WFF8Ldd8Nhh8Hf/ubNV8658itticPMtgCXEZqZPgKeNrOFkkZL6hVt1g1YLOlj4EBgW3eqpKaEGsu/8x06R9L7wPtAPeCOdJ1DcdWrB/ffD2+/He4kOu886NoV3nsv7siccy71VBEmWcnKyrLc3NwS+axffgl9ICNGwHffwaWXwujR4XZe55wrSyTNNbOs/OVxd46XO5UqwUUXhearYcNg/Hho0QIeeSQkFeecK+s8caTJ/vuHpJGbC82bwwUXQJcuMG9e3JE559ye8cSRZu3awWuvwcSJsHQpZGXB8OHw7bdxR+acc7vHE0cJqFQJBg0KQ5VccQU88EBovpowAbZu3fX+zjlXmnjiKEH77htu2Z03L4y6e/HFcNRR4XkQ55wrKzxxxKBtW5g1K8xjsXJlSB5DhkAKH3B3zrm08cQREwnOPRcWLQpPnE+cGJqvxo/35ivnXOnmiSNmderA2LHhYcH27eGyy0IH+htvxB2Zc84VzBNHKdGqFbzyCjz9NHzzTbh1d/Bg+OqruCNzzrkdeeIoRSQ46yz46KPw5PkTT4Tmq//3/2DLlrijc865wBNHKVSrFtx5J7z/fug4v+qq8DzI7NlxR+acc544SrXDDoN//Qv+8Q/YsAGOOy7Mc/Hll3FH5pyryDxxlHISnHEGfPgh3HILPPtsSChjx8Lmzbve3znnUs0TRxlRs2YYZXfhwlDzuO66MHnUq6/GHZlzrqLxxFHG/OpX8MIL8Pzz8NNPcNJJcPbZ8MUXu97XOedSwRNHGXXaaaH2MXp0SCItW8If/hCSiXPOpZMnjjKsRo3Q7/HRR3DKKXDjjWE4k+nT447MOVeepTVxSOouabGkJZJGFLC+iaRXJS2QNEtSRsK6rZLmR68pCeXNJL0dHfOpaD7zCq1pU3juOZg2Lcx13r176FBftizuyJxz5VHaEoekysB4oAfQChggqVW+zcYCj5lZW2A0cGfCuk1mlhm9eiWU/y/wFzM7FPgOuDBd51DWdO8env34n/+Bl16Cww+H22+HH3+MOzLnXHmSzhpHJ2CJmS01s5+BSUDvfNu0AmZE72cWsH4HkgScADwTFT0K9ElZxOVA9eqhyWrRIjj9dLj11jCE+wsvxB2Zc668SGfiaAgk3uuzIipL9B7QN3p/BlBbUt1ouYakXElvScpLDnWBtWaWNwBHQccEQNLQaP/c1RVwvPJGjcK4Vy+/DNWqhSRy+unw6adxR+acK+vi7hz/HXCcpHeB44CVQN6g4k3MLAs4F7hb0q+SObCZTTCzLDPLql+/fkqDLktOOimMvHvXXWEOkCOOCLWQjRvjjsw5V1alM3GsBBolLGdEZduY2Zdm1tfM2gEjo7K10c+V0c+lwCygHbAG2FdSlcKO6XZWrRr87neh+erMM0O/R6tWMHly6Ex3zrlkpDNxzAGaR3dBVQP6A1MSN5BUT1JeDDcCD0fl+0mqnrcN0AX40MyM0BfSL9pnEPDPNJ5DudKwYZh1cNYsqF073HnVsyd8/HHckTnnypK0JY6oH+IyYDrwEfC0mS2UNFpS3l1S3YDFkj4GDgTGROWHA7mS3iMkij+Y2YfRuhuAayQtIfR5PJSucyivjjsuzHt+991hwqjWrUOH+g8/xB2Zc64skFWAtoqsrCzLzc2NO4xS6b//DXN/PPooZGTAn/8M/fqFwRWdcxWbpLlRX/MO4u4cdzE76KAw3/nrr0O9emHcq5NPDk+jO+dcQTxxOCBMVZubC3/9K8ydG4Yuue66MA+Ic84l8sThtqlcGS69NHSWDxoU5vw47LAwhW0FaNF0zhWTJw63k/r14cEH4a234OCDw6yDxx8PH3wQd2TOudLAE4crVOfO8PbbcP/9YQyszMww//m6dXFH5pyLkycOV6TKlWHo0NB8NWQIjBsHLVqEu7B++SXu6JxzcfDE4Yqlbl24916YMweaNYPBg+HYY2H+/Lgjc86VNE8cLikdOoSHBh9+GD75JCxfdhl8913ckTnnSoonDpe0SpXg/PNh8WK45JJQE2nRAh56yJuvnKsIPHG43bbffvB//xeGL2nZEi66KIzG6xNHOVe+eeJwe+zII2H2bLjvPpg5Ey680J/7cK48q7LrTZzbNQkuvhi++QZuvjlMW3vzzXFH5ZxLB08cLqVuuimMc3XLLaH5ql+/Xe/jnCtbvKnKpZQUnjo/+mgYODCMf+WcK188cbiUq1EDnnsuDF3Suzes9DkanStXPHG4tDjwQHj++TA8Se/ePse5c+WJJw6XNm3bwpNPhtt1Bw3yZzycKy/SmjgkdZe0WNISSSMKWN9E0quSFkiaJSkjKs+U9KakhdG6cxL2mSjpM0nzo1dmOs/B7ZnTT4c//hGeeQZGjYo7GudcKqTtripJlYHxwMnACmCOpCkJc4cDjAUeM7NHJZ0A3AmcB2wEBprZJ5IOBuZKmm5ma6P9rjOzZ9IVu0uta6+FDz+E228Pd1qde27cETnn9kQ6axydgCVmttTMfgYmAb3zbdMKmBG9n5m33sw+NrNPovdfAl8D9dMYq0sjKTwc2LUrXHBBmOfDOVd2FStxSNpbUqXofQtJvSRV3cVuDYEvEpZXRGWJ3gP6Ru/PAGpLqpvvszsB1YBPE4rHRE1Yf5FUvZCYh0rKlZS7evXqXYTq0q1aNXj2WWjYEPr0gc8/jzsi59zuKm6NYzZQQ1JD4CVCc9LEFHz+74DjJL0LHAesBLbmrZTUAHgcON/M8rpWbwRaAh2B/YEbCjqwmU0wsywzy6pf3ysrpUG9euFOq02boFcv+P77uCNyzu2O4iYOmdlGQu3gHjM7CzhiF/usBBolLGdEZduY2Zdm1tfM2gEjo7K1AJLqAC8CI83srYR9VlnwE/AIoUnMlRGtWsFTT4UZBbOz/U4r58qiYicOSUcD2YQvc4DKu9hnDtBcUjNJ1YD+wJR8B62X1wRGqEk8HJVXA54jdJw/k2+fBnkBAX0Anwm7jOneHf7yF5gyBW68Me5onHPJKm7iuIrwxf6cmS2UdAihM7tQZrYFuAyYDnwEPB3tO1pSr2izbsBiSR8DBwJjovKzga7A4AJuu82R9D7wPlAPuKOY5+BKkcsvh2HDwq26EyfGHY1zLhmyJMe/jmoItcxsfXpCSr2srCzL9UGTSp3Nm6FHjzAk+6uvhqlonXOlh6S5ZpaVv7y4d1U9IamOpL0JTUMfSrou1UG6iqVqVfj738Mc5mecAUuXxh1RycnJgaZNw2yKTZuGZefKiuI2VbWKahh9gGlAM8KdVc7tkf32C3dabd0anjJfX2bqsbsvJweGDoXly8OEV8uXh2VPHq6sKG7iqBo9t9EHmGJmmwGf482lRIsWYUiSxYuhf3/YsiXuiNJr5MidB33cuDGUO1cWFDdx3A8sA/YGZktqAlSAvw1dSTnxRBg/HqZNg+vKeSNoYQ8/+kORrqwoVuIws3Fm1tDMekbPUCwHjk9zbK6CufhiuOIKuPtumDAh7mjSp3Hj5MqdK22K2zm+j6Q/5w3hIelPhNqHcyn1pz+F5zwuvRRmzNj19mXRmDFQs+aOZTVrhnLnyoLiNlU9DGwgPF9xNqGZ6pF0BeUqripVYNKk0O/Rrx988kncEaVednaoUTVpEgaAbNIkLGdnxx2Zc8VTrOc4JM03s8xdlZVW/hxH2bN0KXTqBHXrhtF099sv7oicq3j26DkOYJOkXyccrAuwKVXBOZffIYfAP/4Bn30GZ50VHhZ0zpUOxU0cw4DxkpZJWgb8Fbg4bVE5R5i/4/77w1PlV14ZnnlwzsWvWDMAmtl7wJHRiLWY2XpJVwEL0hmcc+efDx99BHfdFUbWveyyuCNyziU1A6CZrU8Yo+qaNMTj3E7uvDPM33HllTB9etzROOf2ZOpYpSwK54pQuTL87W/QujWcfXaogTjn4rMnicNbnF2JqV07zN9RowacdhqsWRN3RM5VXEUmDkkbJK0v4LUBOLiEYnQOCM87TJ4MK1dC377w889xR+RcxVRk4jCz2mZWp4BXbTMrVse6c6l09NHw0ENhDo/hw/1OK+fisCdNVbskqbukxZKWSBpRwPomkl6VtEDSLEkZCesGSfokeg1KKO8g6f3omOOiKWRdBZKdHUaSffhh+POf447GuYonbYlDUmVgPNADaAUMkNQq32ZjCfOKtwVGA3dG++4P3AZ0BjoBt0nKe3b4XmAI0Dx6dU/XObjSa/RoOPPMMMipLUsAABUZSURBVJLuCy/EHY1zFUs6axydgCVmttTMfgYmAb3zbdMKyBvKbmbC+t8AL5vZt2b2HfAy0F1SA6COmb1lYayUxwhzhLgKplIlePRRaNcOBgyA99+POyLnKo50Jo6GwBcJyyuiskTvAX2j92cAtSXVLWLfhtH7oo4JgKSheaP5rl69erdPwpVee+8d7rSqXTvMHvj113FH5FzFkNY+jmL4HXCcpHeB44CVwNZUHNjMJphZlpll1a9fPxWHdKVQw4YheXz1VZi3/Mcf447IufIvnYljJdAoYTkjKtvGzL40s75m1g4YGZWtLWLfldH7Qo/pKp6sLHjsMXjjDRgyxO+0ci7d0pk45gDNJTWTVA3oD0xJ3EBSPUl5MdxImPcDYDpwiqT9ok7xU4DpZrYKWC/pqOhuqoHAP9N4Dq6MOOus0GH+t7/BH/4QdzTOlW9pSxxmtgW4jJAEPgKeNrOFkkZL6hVt1g1YLOlj4EBgTLTvt8DthOQzBxgdlQFcAjwILAE+Baal6xxc2XLzzaGj/KabwpDszrn0KNZETmWdT+RUcWzaBMcfH+6yeu01aN8+7oicK7v2dCIn58qEvfYKw5LUrRtG1F21Ku6InCt/PHG4cuegg8KdVmvXQu/eoRbinEsdTxyuXMrMDB3lubkweLDfaeVcKnnicOVWnz5hEqinn4bf/z7uaJwrP3yEW1euXX99mPjp97+Hli2hf/+4I3Ku7PMahyvXJLj/fujSJcxf/s47cUfkXNnnicOVe9Wrw3PPhU7z3r3hiy92vY9zrnCeOFyFUL8+PP88/PBDuE33hx/ijsi5sssTh6swWreGSZNgwQL47W/hl1/ijsi5sskTh6tQevaEP/0pPCR4881xR+Nc2eR3VbkK58or4cMPw626LVvCwIFxR+Rc2eI1DlfhSDB+PHTrFoZh/89/4o7IubLFE4erkKpWhWeegcaNwwRQy5bFHZFzZYcnDldh1a0b7rT6+ecw9ez69XFH5FzZ4InDVWgtW8Lf/x6eLj/3XNiakomLnSvfPHG4Cu/kk2HcOHjxxTBEiXOuaH5XlXPAJZeEWsef/wyHHw4XXRR3RM6VXmmtcUjqLmmxpCWSRhSwvrGkmZLelbRAUs+oPFvS/ITXL5Iyo3WzomPmrTsgnefgKo6//AVOOQWGD4dZs+KOxrnSK22JQ1JlYDzQA2gFDJDUKt9mNxPmIm8H9AfuATCzHDPLNLNM4DzgMzObn7Bfdt56M/s6XefgKpYqVeCpp+DQQ+HMM2HJkrgjcq50SmeNoxOwxMyWmtnPwCSgd75tDKgTvd8H+LKA4wyI9nUu7fbdN9xpBeFOq7Vr443HudIonYmjIZA4DumKqCzRKOC3klYAU4HLCzjOOcCT+coeiZqpbpGkgj5c0lBJuZJyV69evVsn4CqmQw+FZ58NNY5zzoEtW+KOyLnSJe67qgYAE80sA+gJPC5pW0ySOgMbzeyDhH2yzawNcGz0Oq+gA5vZBDPLMrOs+vXrp+8MXLnUrRvcdx+89BJcfXXc0ThXuqQzcawEGiUsZ0RliS4EngYwszeBGkC9hPX9yVfbMLOV0c8NwBOEJjHnUu7CC+Gaa+Cvf4V77ok7GudKj3QmjjlAc0nNJFUjJIEp+bb5HDgRQNLhhMSxOlquBJxNQv+GpCqS6kXvqwKnAR/gXJr88Y9w6qlwxRXw8stxR+Nc6ZC2xGFmW4DLgOnAR4S7pxZKGi2pV7TZtcAQSe8RahaDzcyidV2BL8xsacJhqwPTJS0A5hNqMA+k6xycq1wZnngiPNtx1lmwaFHcETkXP23/ni6/srKyLDc3N+4wXBm2bBl06gT77ANvvRXGuXKuvJM018yy8pf7k+POFUPTpmHe8hNOgH79YPp0qFYt7qhcfmZhZse819athS8Xd10qjhHnZ99xBxx0UGqvsycO54qpSxd48MEw8dNll8H994e5PVz6mMEnn8C0aTB1KsydG26PLuxLsgI0oFCp0o6vypWLfj9ipzE79pwnDueScN55YUyrO++EVq3gqqvijqj82bQpDPkydWpIGJ9+GspbtoS+faFmzV1/aRbnCzXuY+zO8aXS8ceKJw7nknTHHSF5XHsttGgR5jF3e2bp0pAopk6FmTPhxx9hr71C0+A110CPHtCsWdxRujyeOJxLUqVK8PjjcOyx0L8/vPEGtG4dd1Rly08/wezZ25PFxx+H8ubNYejQkIyPOw5q1Ig3TlcwTxzO7YZatWDKlHCn1emnwzvvgA9QULTly7c3P736KmzcCNWrw/HHw6WXhlpF8+ZxR+mKwxOHc7upUSP45z/DX8ZnnBG+DKtXjzuq0uPnn+H117cniw8/DOXNmsH554daRbduoc/ClS2eOJzbA506wcSJoclq6NDwvjR0XsZlxYrtd0C98gp8/324bblr1zA5Vs+eoV+oIl+j8sATh3N76JxzQmf5738f7rS64Ya4Iyo5mzeHPp68ZPH++6G8cWPIzg6J4oQTQtOeKz88cTiXArfeGpLHjTfCYYdBnz5xR5Q+q1aFRDFtWhg9eP36MAnWscfCXXeFvopWrbxWUZ554nAuBSpVCs1Un30Gv/1taNvPzIw7qtTYsgXefnt7X8W774bygw+Gs88OtYoTT4Q6dYo+jis/PHE4lyJ77RU6yzt2hF69wp1WqR7qoaR8/TX8618hWbz0Enz3XXgI7ZhjwsOPPXtCmzZeq6ioPHE4l0INGoSpZ3/969BcNXNmSCil3datMGfO9r6KvDFBDzoonEePHnDyyWFqXec8cTiXYu3ahQcEzzwzTAaVk1M6/zL/5pswWOO0aaF2sWZNaHI76qjwdHyPHqG5rVLc84S6UscTh3Np0LcvjBkDI0eGuTxuuSXuiMIggPPmbX9a+513wqCA9euHpqeePeGUU2D//eOO1JV2njicS5Mbbwx3Wt16a7jT6uyzSz6Gb78NfRR5tYqvvw61n06d4LbbQrLo0MFrFS45njicSxMJHnggDOA3aFB4Yrpjx/R+phnMn7/9Dqg33ww1jf33h+7dQ/PTb37jw6O4PZPWxCGpO/D/gMrAg2b2h3zrGwOPAvtG24wws6mSmhKmm10cbfqWmQ2L9ukATAT2AqYCV1pFmMbQlUk1aoQJoDp2hN69Qwd0w4ap/Yx168J86FOnhlrFqlWhvEOH0FTWo0eoYVSunNrPdRVX2iqokioD44EeQCtggKRW+Ta7mTAXeTugP3BPwrpPzSwzeg1LKL8XGAI0j17d03UOzqXCAQfACy/Ahg3hNt0fftiz45nBggXwv/8bxsmqWzfMh/7cc+EhvIkTQ/LIzYXRo+Hoo8t+0sjJCbMwVqoUfubkxB1RxZbOGkcnYImZLQWQNAnoDXyYsI0BeY8N7QN8WdQBJTUA6pjZW9HyY0AfYFpqQ3cutdq0gSefDIlj0CB4+unk+hU2bAhjP+XdLrtyZSjPzITrrw99FUcdFZ7gLm9ycsI4YBs3huXly8MyhGFNXMlL53+zhsAXCcsrgM75thkFvCTpcmBv4KSEdc0kvQusB242s9eiY67Id8wCK/6ShgJDARo3brz7Z+Fcipx2WhiS43e/Cx3md9xR+LZmoWM9r6/itdfCuFC1a4c7n3r0CH0WqW72Ko1GjtyeNPJs3BjKPXHEI+6/TwYAE83sT5KOBh6X1BpYBTQ2szVRn8ZkSUckc2AzmwBMAMjKyvI+EFcqXHNNGF58zJhwm27iF98PP8CMGduTxfLlobx1a7j66pAsunSBqlXjiT0un3+eXLlLv3QmjpVAo4TljKgs0YVEfRRm9qakGkA9M/sa+CkqnyvpU6BFtH/GLo7pXKklwb33wpIl4eHA6tXDUORTp8K//x3msNh7bzjpJLjpppAsGjXa9XHLs8aNtyfR/OUuHulMHHOA5pKaEb7c+wPn5tvmc+BEYKKkw4EawGpJ9YFvzWyrpEMIneBLzexbSeslHQW8DQwE/i+N5+BcylWrBs8+C507h05tCLWPyy4LfRW//rVPCJVozJgd+zggTP40Zkx8MVV0aUscZrZF0mXAdMKttg+b2UJJo4FcM5sCXAs8IOlqQkf5YDMzSV2B0ZI2A78Aw8zs2+jQl7D9dtxpeMe4K4Pq1Qud3TNmhPkqmjWLO6LSK685b+TI0DzVuHFIGt6/ER9VhEcgsrKyLDdv1DbnnHPFImmumWXlL/eBBpxzziXFE4dzzrmkeOJwzjmXFE8czjnnkuKJwznnXFI8cTjnnEuKJw7nnHNJ8cThnHMuKZ44nHPOJcUTh3POuaR44nDOOZcUTxzOOeeS4onDOedcUjxxOOecS4onDuecc0nxxOGccy4paU0ckrpLWixpiaQRBaxvLGmmpHclLZDUMyo/WdJcSe9HP09I2GdWdMz50euAdJ6Dc865HaVt6lhJlYHxwMnACmCOpClm9mHCZjcDT5vZvZJaAVOBpsA3wOlm9qWk1oTpZxsm7JdtZj6ln3POxSCdNY5OwBIzW2pmPwOTgN75tjGgTvR+H+BLADN718y+jMoXAntJqp7GWJ1zzhVTOhNHQ+CLhOUV7FhrABgF/FbSCkJt4/ICjnMmMM/MfkooeyRqprpFkgr6cElDJeVKyl29evVun4Rzzrkdxd05PgCYaGYZQE/gcUnbYpJ0BPC/wMUJ+2SbWRvg2Oh1XkEHNrMJZpZlZln169dP2wk451xFk87EsRJolLCcEZUluhB4GsDM3gRqAPUAJGUAzwEDzezTvB3MbGX0cwPwBKFJzDnnXCQnB5o2hUqVws+cnNQeP52JYw7QXFIzSdWA/sCUfNt8DpwIIOlwQuJYLWlf4EVghJn9J29jSVUk5SWWqsBpwAdpPAfnnCtTcnJg6FBYvhzMws+hQ1ObPNKWOMxsC3AZ4Y6ojwh3Ty2UNFpSr2iza4Ehkt4DngQGm5lF+x0K3JrvttvqwHRJC4D5hBrMA+k6B+ecK2tGjoSNG3cs27gxlKeKwvd0+ZaVlWW5uX73rnOu/KtUKdQ08pPgl1+SO5akuWaWtdNn7G5wzjnnSp/GjZMr3x2eOJxzrhwZMwZq1tyxrGbNUJ4qnjicc64cyc6GCROgSZPQPNWkSVjOzk7dZ6RtyBHnnHPxyM5ObaLIz2sczjnnkuKJwznnXFI8cTjnnEuKJw7nnHNJ8cThnHMuKRXiyXFJq4Hlu7l7PcLEUqWNx5Ucjys5HldyymtcTcxsp+HFK0Ti2BOScgt65D5uHldyPK7keFzJqWhxeVOVc865pHjicM45lxRPHLs2Ie4ACuFxJcfjSo7HlZwKFZf3cTjnnEuK1zicc84lxROHc865pHjiiEjqLmmxpCWSRhSwvrqkp6L1b0tqWkriGixpdcIUuxeVQEwPS/paUoHzvSsYF8W8QFL7dMdUzLi6SVqXcK1uLaG4GkmaKelDSQslXVnANiV+zYoZV4lfM0k1JL0j6b0ort8XsE2J/z4WM64S/31M+OzKkt6V9EIB61J7vcyswr+AysCnwCFANeA9oFW+bS4B7ove9weeKiVxDQb+WsLXqyvQHvigkPU9gWmAgKOAt0tJXN2AF2L4/9UAaB+9rw18XMC/Y4lfs2LGVeLXLLoGtaL3VYG3gaPybRPH72Nx4irx38eEz74GeKKgf69UXy+vcQSdgCVmttTMfgYmAb3zbdMbeDR6/wxwoiSVgrhKnJnNBr4tYpPewGMWvAXsK6lBKYgrFma2yszmRe83AB8BDfNtVuLXrJhxlbjoGnwfLVaNXvnv4inx38dixhULSRnAqcCDhWyS0uvliSNoCHyRsLyCnX+Btm1jZluAdUDdUhAXwJlR88YzkhqlOabiKG7ccTg6amqYJumIkv7wqImgHeGv1USxXrMi4oIYrlnU7DIf+Bp42cwKvV4l+PtYnLggnt/Hu4HrgV8KWZ/S6+WJo+x7HmhqZm2Bl9n+V4Xb2TzC2DtHAv8HTC7JD5dUC3gWuMrM1pfkZxdlF3HFcs3MbKuZZQIZQCdJrUvic3elGHGV+O+jpNOAr81sbro/K48njmAlkPiXQUZUVuA2kqoA+wBr4o7LzNaY2U/R4oNAhzTHVBzFuZ4lzszW5zU1mNlUoKqkeiXx2ZKqEr6cc8zsHwVsEss121VccV6z6DPXAjOB7vlWxfH7uMu4Yvp97AL0krSM0Jx9gqS/5dsmpdfLE0cwB2guqZmkaoTOoyn5tpkCDIre9wNmWNTTFGdc+drBexHaqeM2BRgY3Sl0FLDOzFbFHZSkg/LadSV1Ivz/T/uXTfSZDwEfmdmfC9msxK9ZceKK45pJqi9p3+j9XsDJwKJ8m5X472Nx4orj99HMbjSzDDNrSviOmGFmv823WUqvV5Xd3bE8MbMtki4DphPuZHrYzBZKGg3kmtkUwi/Y45KWEDpg+5eSuK6Q1AvYEsU1ON1xSXqScLdNPUkrgNsIHYWY2X3AVMJdQkuAjcD56Y6pmHH1A4ZL2gJsAvqXQPKH8BfhecD7Ufs4wE1A44TY4rhmxYkrjmvWAHhUUmVConrazF6I+/exmHGV+O9jYdJ5vXzIEeecc0nxpirnnHNJ8cThnHMuKZ44nHPOJcUTh3POuaR44nDOOZcUTxzO7SZJWxNGQZ2vAkYv3oNjN1Uho/w6Fzd/jsO53bcpGn7CuQrFaxzOpZikZZL+KOn9aP6GQ6PyppJmRAPgvSqpcVR+oKTnooEE35N0THSoypIeUJj74aXoaWUkXaEwh8YCSZNiOk1XgXnicG737ZWvqeqchHXrzKwN8FfCyKUQBgl8NBoALwcYF5WPA/4dDSTYHlgYlTcHxpvZEcBa4MyofATQLjrOsHSdnHOF8SfHndtNkr43s1oFlC8DTjCzpdEggv81s7qSvgEamNnmqHyVmdWTtBrISBgcL2+Y85fNrHm0fANQ1czukPQv4HvCSLWTE+aIcK5EeI3DufSwQt4n46eE91vZ3id5KjCeUDuZE4126lyJ8cThXHqck/Dzzej9G2wfXC4beC16/yowHLZNFLRPYQeVVAloZGYzgRsIw2PvVOtxLp38LxXndt9eCaPKAvzLzPJuyd1P0gJCrWFAVHY58Iik64DVbB8B90pggqQLCTWL4UBhQ6pXBv4WJRcB46K5IZwrMd7H4VyKRX0cWWb2TdyxOJcO3lTlnHMuKV7jcM45lxSvcTjnnEuKJw7nnHNJ8cThnHMuKZ44nHPOJcUTh3POuaT8fxZVJUMtzIWdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots \n",
    "plt.plot(range(0, epoch_count-1), train_losses, 'bo', label='Training loss')\n",
    "plt.plot(range(0, epoch_count-1), test_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "qYuCf1D6APOM",
    "outputId": "8a47c929-349f-4296-cbdb-4825b2b4ff5e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, epoch_count-1), train_accuracies, 'bo', label='Training accuracy')\n",
    "plt.plot(range(0, epoch_count-1), test_accuracies, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracies')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Fu_Dgl7qKjN",
    "outputId": "a306c66f-d897-4974-f87f-462c079716c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "model.load_state_dict(torch.load('drive/MyDrive/TwitterProject/saved_models/BERT-b1-r1-h256-d6-blr1e-5.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "kxzVKP2eEAaz",
    "outputId": "c868e68f-da3f-4769-da6e-9e3ae2d5074e"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e4c531554bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                             include_bert_masks=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-56554aab73d1>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, iterator, criterion, device, include_bert_masks)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mall_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: concatenate() got multiple values for argument 'axis'"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, confusion, predictions, labels = test(model=model,\n",
    "                            iterator=test_loader,\n",
    "                            criterion=criterion,\n",
    "                            device=DEVICE,\n",
    "                            include_bert_masks=True)\n",
    "\n",
    "print(f'Test Loss:  {test_loss:.3f} | Test Accuracy:  {test_acc * 100:.2f}%')\n",
    "print(f\"F1: {f1}\")\n",
    "print(f'Test confusion:\\n{confusion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWd533cW69ZR"
   },
   "outputs": [],
   "source": [
    "def predict(tweet, header_id, print_results = False):\n",
    "    labels = [\"agree\", \"disagree\", \"no_stance\", \"not_relevant\"]\n",
    "\n",
    "    prediction = model.predict(tweet, header_id)\n",
    "    if print_results:\n",
    "        print(\"Target: \" + targets[target_idx.index(header_id)])\n",
    "        print(\"Tweet: \" + tweet)\n",
    "        print(labels[torch.argmax(prediction, dim=-1)])\n",
    "    return labels[torch.argmax(prediction, dim=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjyuDH8X5lPX"
   },
   "outputs": [],
   "source": [
    "tweets = dict()\n",
    "outputs = []\n",
    "with open('drive/MyDrive/TwitterProject/test_data/test_tweets.jsonl') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        tweets[obj['id']] = obj['text']\n",
    "\n",
    "with open('drive/MyDrive/TwitterProject/test_data/test_candidates.jsonl') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        tweet_id = obj['tweet_id']\n",
    "        tweet = tweets[tweet_id]\n",
    "        m_id = int(obj['m_id'])\n",
    "        prediction = predict(tweet, m_id)\n",
    "        output = dict()\n",
    "        output['tweet_id'] = tweet_id\n",
    "        output['m_id'] = str(m_id)\n",
    "        output['m_label'] = prediction\n",
    "        outputs.append(json.dumps(output))\n",
    "\n",
    "with open('drive/MyDrive/TwitterProject/test_data/output/X1_test_outputs.jsonl', 'w+') as f:\n",
    "    for line in outputs:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h__9Nb41zOeb"
   },
   "outputs": [],
   "source": [
    "tweet = \"@JCope222 Vaccine is untested for safety. People have died in he trials. Natural immunity scores 99.975% recovery from Covid for your age group\"\n",
    "header_id = 1\n",
    "\n",
    "predict(tweet, header_id)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT Stance Detection",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
